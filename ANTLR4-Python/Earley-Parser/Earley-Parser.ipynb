{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "with open('../../style.css', 'r') as file:\n",
    "    css = file.read()\n",
    "HTML(css)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing an Earley Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Grammar for Grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our grammar is stored in the file `Grammar.g4`.  This grammar describes the lexical structure of the grammars for the language \n",
    "`C` that is contained in the file `c-grammar.g`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat -n Grammar.g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat simple.g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by generating both scanner and parser.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!antlr4 -Dlanguage=Python3 Grammar.g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GrammarLexer  import GrammarLexer\n",
    "from GrammarParser import GrammarParser\n",
    "import antlr4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `parse_grammar` takes a `filename` as its argument and returns the grammar that is stored in the given file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_grammar(filename):\n",
    "    input_stream  = antlr4.FileStream(filename)\n",
    "    lexer         = GrammarLexer(input_stream)\n",
    "    token_stream  = antlr4.CommonTokenStream(lexer)\n",
    "    parser        = GrammarParser(token_stream)\n",
    "    grammar       = parser.start()\n",
    "    return grammar.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_grammar('simple.g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarleyItem():\n",
    "    def __init__(self, variable, alpha, beta, index):\n",
    "        self.mVariable = variable\n",
    "        self.mAlpha    = alpha\n",
    "        self.mBeta     = beta\n",
    "        self.mIndex    = index\n",
    "        \n",
    "    def __repr__(self):\n",
    "        alphaStr = ''\n",
    "        for x in self.mAlpha:\n",
    "            alphaStr += x\n",
    "        betaStr = ''\n",
    "        for x in self.mBeta:\n",
    "            betaStr += x\n",
    "        return f'<{self.mVariable} -> {alphaStr} â€¢ {betaStr}, {self.mIndex}>'\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, EarleyItem):\n",
    "            return self.mVariable == other.mVariable and \\\n",
    "                   self.mAlpha    == other.mAlpha    and \\\n",
    "                   self.mBeta     == other.mBeta     and \\\n",
    "                   self.mIndex    == other.mIndex\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def __ne__(self, other):\n",
    "        return not self.__eq__(other)\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isComplete(self):\n",
    "    return self.mBeta == ()\n",
    "\n",
    "EarleyItem.isComplete = isComplete\n",
    "del isComplete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `sameVar`$(C)$ checks, whether the item following the dot is the same as the variable \n",
    "given as argument.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sameVar(self, C):\n",
    "    return len(self.mBeta) > 0 and self.mBeta[0] == C\n",
    "\n",
    "EarleyItem.sameVar = sameVar\n",
    "del sameVar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `scan` checks, whether the item following the dot matches the token $t$\n",
    "that is given as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan(self, t):\n",
    "    if len(self.mBeta) > 0:\n",
    "        return self.mBeta[0] == t or self.mBeta[0] == \"'\" + t + \"'\"\n",
    "    return False\n",
    "\n",
    "EarleyItem.scan = scan\n",
    "del scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return the name of the variable following the dot.  If there is no variable \n",
    "following the dot, return `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nextVar(self):\n",
    "    if len(self.mBeta) > 0:\n",
    "        var = self.mBeta[0]\n",
    "        if var[0] != \"'\" and var.islower():\n",
    "            return var\n",
    "    return None\n",
    "\n",
    "EarleyItem.nextVar = nextVar\n",
    "del nextVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moveDot(self):\n",
    "    return EarleyItem(self.mVariable, \n",
    "                      self.mAlpha + (self.mBeta[0],), \n",
    "                      self.mBeta[1:], \n",
    "                      self.mIndex)\n",
    "\n",
    "EarleyItem.moveDot = moveDot\n",
    "del moveDot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grammar():\n",
    "    def __init__(self, Rules):\n",
    "        self.mRules = Rules   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startItem(self):\n",
    "    return EarleyItem('Start', (), (self.startVar(),), 0)\n",
    "\n",
    "Grammar.startItem = startItem\n",
    "del startItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finishItem(self):\n",
    "    return EarleyItem('Start', (self.startVar(),), (), 0)\n",
    "\n",
    "Grammar.finishItem = finishItem\n",
    "del finishItem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first rule has to start with the start variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startVar(self):\n",
    "    return self.mRules[0][0]\n",
    "\n",
    "Grammar.startVar = startVar\n",
    "del startVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toString(self):\n",
    "    result = ''\n",
    "    for head, *body in self.mRules:\n",
    "        result += f'{head}: {body};\\n'\n",
    "    return result\n",
    "\n",
    "Grammar.__str__ = toString\n",
    "del toString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarleyParser():\n",
    "    def __init__(self, grammar, TokenList):\n",
    "        self.mGrammar   = grammar \n",
    "        self.mString    = [None] + TokenList  # dirty hack so mString[1] is first char\n",
    "        self.mStateList = [ set() for i in range(len(TokenList)+1) ] \n",
    "        print('Grammar:\\n')\n",
    "        print(self.mGrammar)\n",
    "        print(f'Input: {self.mString}\\n')\n",
    "        self.mStateList[0] = { self.mGrammar.startItem() }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method implements Earley's algorithm.  For all states $Q_i$ we \n",
    "apply the completion operation followed by the prediction operation.\n",
    "This is done until no more no states are added to $Q_i$.  The inner `while`\n",
    "loop is not necessary if the grammar contains not $\\varepsilon$-rules.  \n",
    "Finally, the scanning operation is applied to $Q_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(self):\n",
    "    \"run Earley's algorithm\"\n",
    "    n = len(self.mString)\n",
    "    for i in range(0, n):\n",
    "        if i + 1 < n:\n",
    "            print('_' * 80)\n",
    "            print(f'next token = {self.mString[i+1]}')\n",
    "            print('_' * 80)\n",
    "        change = True\n",
    "        while change:\n",
    "            change = self.complete(i)\n",
    "            change = self.predict(i) or change\n",
    "        self.scan(i)\n",
    "        # print states\n",
    "        for i in range(n):\n",
    "            print(f'\\nQ{i}:')\n",
    "            Qi = self.mStateList[i]\n",
    "            for item in Qi: \n",
    "                print(item)\n",
    "    if self.mGrammar.finishItem() in self.mStateList[-1]:\n",
    "        print('Parsing successful!')\n",
    "    else:\n",
    "        print('Parsing failed!')\n",
    "\n",
    "EarleyParser.parse = parse\n",
    "del parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the completion operation on the state $Q_i$.  The parameter $i$\n",
    "is the index of the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(self, i):\n",
    "    change = False\n",
    "    added  = True\n",
    "    Qi     = self.mStateList[i]\n",
    "    while added:\n",
    "        added = False\n",
    "        newQi = set()\n",
    "        for item in Qi:\n",
    "            if item.isComplete():\n",
    "                C  = item.mVariable\n",
    "                j  = item.mIndex\n",
    "                Qj = self.mStateList[j]\n",
    "                for newItem in Qj:\n",
    "                    if newItem.sameVar(C):\n",
    "                        moved = newItem.moveDot()\n",
    "                        newQi.add(moved)\n",
    "        if not (newQi <= Qi):\n",
    "            change = True\n",
    "            added  = True\n",
    "            print(\"completion:\")\n",
    "            for newItem in newQi:\n",
    "                if newItem not in Qi:\n",
    "                    print(newItem)\n",
    "            self.mStateList[i] |= newQi\n",
    "            Qi = self.mStateList[i]\n",
    "        return change\n",
    "    \n",
    "EarleyParser.complete = complete\n",
    "del complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the prediction operation to the state $Q_i$.  The parameter $i$\n",
    "is the index of the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, i):\n",
    "    change = False\n",
    "    added  = True\n",
    "    Qi     = self.mStateList[i]\n",
    "    while added:\n",
    "        added = False\n",
    "        newQi = set()\n",
    "        for item in Qi:\n",
    "            c = item.nextVar()\n",
    "            if c != None:\n",
    "                for rule in self.mGrammar.mRules:\n",
    "                    if c == rule[0]:\n",
    "                        newQi.add(EarleyItem(c, (), rule[1:], i))\n",
    "        if not (newQi <= Qi):\n",
    "            change = True\n",
    "            added  = True\n",
    "            print(\"prediction:\")\n",
    "            for newItem in newQi:\n",
    "                if newItem not in Qi:\n",
    "                    print(newItem)\n",
    "            self.mStateList[i] |= newQi\n",
    "            Qi = self.mStateList[i]\n",
    "    return change\n",
    "\n",
    "EarleyParser.predict = predict\n",
    "del predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the scanning operation on the state Qi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan(self, i):\n",
    "    Qi = self.mStateList[i]\n",
    "    n  = len(self.mString)\n",
    "    if i + 1 < n:\n",
    "        a = self.mString[i+1]\n",
    "        for item in Qi:\n",
    "            if item.scan(a):\n",
    "                self.mStateList[i+1].add(item.moveDot())\n",
    "                print('scanning:')\n",
    "                print(item.moveDot())\n",
    "\n",
    "EarleyParser.scan = scan\n",
    "del scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    '''Transform the string s into a list of tokens.  The string s\n",
    "       is supposed to represent an arithmetic expression.\n",
    "    '''\n",
    "    lexSpec = r'''([ \\t]+)        |  # blanks and tabs\n",
    "                  ([1-9][0-9]*|0) |  # number\n",
    "                  ([()])          |  # parentheses \n",
    "                  ([-+*/])        |  # arithmetical operators\n",
    "                  (.)                # unrecognized character\n",
    "               '''\n",
    "    tokenList = re.findall(lexSpec, s, re.VERBOSE)\n",
    "    result    = []\n",
    "    for ws, number, parenthesis, operator, error in tokenList:\n",
    "        if ws:        # skip blanks and tabs\n",
    "            continue\n",
    "        elif number:\n",
    "            result += [ 'NUMBER' ]\n",
    "        elif parenthesis:\n",
    "            result += [ parenthesis ]\n",
    "        elif operator:\n",
    "            result += [ operator ]\n",
    "        else:\n",
    "            result += [ f'ERROR({error})']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize('1 + 2 * 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(file, word): \n",
    "    Rules     = parse_grammar(file)\n",
    "    grammar   = Grammar(Rules)\n",
    "    TokenList = tokenize(word)\n",
    "    ep        = EarleyParser(grammar, TokenList)\n",
    "    ep.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test('simple.g', '1 + 2 * 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command below cleans the directory.  If you are running windows, you have to replace `rm`with `del`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm GrammarLexer.* GrammarParser.* Grammar.tokens GrammarListener.py Grammar.interp\n",
    "!rm -r __pycache__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

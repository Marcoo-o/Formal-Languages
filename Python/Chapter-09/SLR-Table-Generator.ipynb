{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing an SLR-Table-Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Grammar for Grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the following grammar to describe the syntax of a context free grammar.\n",
    "```\n",
    "grammar\n",
    "    : rule\n",
    "    | rule grammar\n",
    "    ;\n",
    "\n",
    "rule\n",
    "    : VARIABLE ':' body_list ';'\n",
    "    ;\n",
    "\n",
    "body_list\n",
    "    : body \n",
    "    | body '|' body_list\n",
    "    ;\n",
    "\n",
    "body\n",
    "    : \n",
    "    | item body\n",
    "    ;\n",
    " \n",
    "item : VARIABLE \n",
    "     | TOKEN  \n",
    "     | LITERAL\n",
    "     ;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the goal is to generate an *SLR-table-generator* we first need to implement a parser for context free grammars.\n",
    "The file `arith.g` in the directory `Examples` contains an example grammar that describes arithmetic expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expr: expr '+' product\n",
      "    | expr '-' product\n",
      "    | product\n",
      "    ;\n",
      " \n",
      "product: product '*' factor\n",
      "       | product '/' factor\n",
      "       | factor\n",
      "       ;\n",
      "       \n",
      "factor: '(' expr ')'\n",
      "      | NUMBER\n",
      "      ;\n"
     ]
    }
   ],
   "source": [
    "!cat Examples/arith.g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use <span style=\"font-variant:small-caps;\">Ply</span> to develop a parser for context free grammars.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ply.lex as lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [ 'VARIABLE',  # r'[a-z][a-z0-9_]*'\n",
    "           'TOKEN',     # r'[A-Z][A-Z0-9_]*'\n",
    "           'LITERAL',   # r\"'.'\"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_VARIABLE = r'[a-z][a-z0-9_]*'\n",
    "t_TOKEN    = r'[A-Z][A-Z0-9_]*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_comment(t):\n",
    "    r'//.*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_LITERAL(t):\n",
    "    r\"'.*?'\"\n",
    "    t.value = t.value[1:-1]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "literals = [':', '|', ';']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ignore = ' \\t\\r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_newline(t):\n",
    "    r'\\n'\n",
    "    t.lexer.lineno += 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_column(token):\n",
    "    program    = token.lexer.lexdata  # the complete string given to the scanner\n",
    "    line_start = program.rfind('\\n', 0, token.lexpos)\n",
    "    return token.lexpos - line_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_error(t):\n",
    "    column = find_column(t)\n",
    "    print(f\"Illegal character '{t.value[0]}' in line {t.lineno}, column {column}.\")\n",
    "    t.lexer.skip(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = 'main'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexer = lex.lex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_scanner(file_name):\n",
    "    with open(file_name, 'r') as handle:\n",
    "        program = handle.read() \n",
    "    print(program)\n",
    "    lexer.input(program)\n",
    "    lexer.lineno = 1          # reset line number\n",
    "    for t in lexer:           # start scanning and collect all tokens\n",
    "        print(t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expr: expr '+' product\n",
      "    | expr '-' product\n",
      "    | product\n",
      "    ;\n",
      " \n",
      "product: product '*' factor\n",
      "       | product '/' factor\n",
      "       | factor\n",
      "       ;\n",
      "       \n",
      "factor: '(' expr ')'\n",
      "      | NUMBER\n",
      "      ;\n",
      "\n",
      "LexToken(VARIABLE,'expr',1,0)\n",
      "LexToken(:,':',1,4)\n",
      "LexToken(VARIABLE,'expr',1,6)\n",
      "LexToken(LITERAL,'+',1,11)\n",
      "LexToken(VARIABLE,'product',1,15)\n",
      "LexToken(|,'|',2,27)\n",
      "LexToken(VARIABLE,'expr',2,29)\n",
      "LexToken(LITERAL,'-',2,34)\n",
      "LexToken(VARIABLE,'product',2,38)\n",
      "LexToken(|,'|',3,50)\n",
      "LexToken(VARIABLE,'product',3,52)\n",
      "LexToken(;,';',4,64)\n",
      "LexToken(VARIABLE,'product',6,68)\n",
      "LexToken(:,':',6,75)\n",
      "LexToken(VARIABLE,'product',6,77)\n",
      "LexToken(LITERAL,'*',6,85)\n",
      "LexToken(VARIABLE,'factor',6,89)\n",
      "LexToken(|,'|',7,103)\n",
      "LexToken(VARIABLE,'product',7,105)\n",
      "LexToken(LITERAL,'/',7,113)\n",
      "LexToken(VARIABLE,'factor',7,117)\n",
      "LexToken(|,'|',8,131)\n",
      "LexToken(VARIABLE,'factor',8,133)\n",
      "LexToken(;,';',9,147)\n",
      "LexToken(VARIABLE,'factor',11,157)\n",
      "LexToken(:,':',11,163)\n",
      "LexToken(LITERAL,'(',11,165)\n",
      "LexToken(VARIABLE,'expr',11,169)\n",
      "LexToken(LITERAL,')',11,174)\n",
      "LexToken(|,'|',12,184)\n",
      "LexToken(TOKEN,'NUMBER',12,186)\n",
      "LexToken(;,';',13,199)\n"
     ]
    }
   ],
   "source": [
    "test_scanner('Examples/arith.g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ply.yacc as yacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 'grammar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_grammar_one(p):\n",
    "    \"grammar : rule\"\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_grammar_more(p):\n",
    "    \"grammar : rule grammar\"\n",
    "    p[0] = p[1] + p[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_rule(p):\n",
    "    \"rule : VARIABLE ':' body_list ';'\"\n",
    "    p[0] = [ (p[1],) + body for body in p[3] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_body_list_one(p):\n",
    "    \"body_list : body\"\n",
    "    p[0] = [p[1]]\n",
    "\n",
    "def p_body_list_more(p):\n",
    "    \"body_list : body '|' body_list \"\n",
    "    p[0] = [p[1]] + p[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_body_empty(p):\n",
    "    \"body : \"\n",
    "    p[0] = ()\n",
    "\n",
    "def p_body_more(p):\n",
    "    \"body : item body\"\n",
    "    p[0] = (p[1],) + p[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_item_variable(p):\n",
    "    \"item : VARIABLE\"\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_item_terminal(p):\n",
    "    \"item : TOKEN\"\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_item_literal(p):\n",
    "    \"item : LITERAL\"\n",
    "    p[0] = p[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_error(t):\n",
    "    column = find_column(t)\n",
    "    if t:\n",
    "        print(f'Syntax error at token \"{t.value}\" in line {t.lineno}, column {column}.')\n",
    "    else:\n",
    "        print('Syntax error at end of input.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating LALR tables\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ply.yacc.LRParser at 0x1064b8ad0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yacc.yacc(write_tables=False, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(file):\n",
    "    lexer.lineno = 1\n",
    "    with open(file, 'r') as handle:\n",
    "        grammar = handle.read() \n",
    "    print(grammar)\n",
    "    ruleList = yacc.parse(grammar)\n",
    "    return ruleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expr: expr '+' product\n",
      "    | expr '-' product\n",
      "    | product\n",
      "    ;\n",
      " \n",
      "product: product '*' factor\n",
      "       | product '/' factor\n",
      "       | factor\n",
      "       ;\n",
      "       \n",
      "factor: '(' expr ')'\n",
      "      | NUMBER\n",
      "      ;\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('expr', 'expr', '+', 'product'),\n",
       " ('expr', 'expr', '-', 'product'),\n",
       " ('expr', 'product'),\n",
       " ('product', 'product', '*', 'factor'),\n",
       " ('product', 'product', '/', 'factor'),\n",
       " ('product', 'factor'),\n",
       " ('factor', '(', 'expr', ')'),\n",
       " ('factor', 'NUMBER')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruleList = parse('Examples/arith.g')\n",
    "ruleList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parser will return a list of grammar rules, where each rule of the form\n",
    "$$ a \\rightarrow \\beta $$\n",
    "is stored as the tuple `(a,) + 𝛽`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_mypy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a few *type aliases* in order to make the types more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variable = str\n",
    "Token    = str\n",
    "Symbol   = Variable | Token\n",
    "Symbols  = tuple[Symbol, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Class `GrammarRule`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `GrammarRule` is used to store a single grammar rule.  As we have to use objects of type `GrammarRule` as *keys* in a dictionary later, we have to provide the methods `__eq__`, `__ne__`, and `__hash__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarRule:\n",
    "    def __init__(self, variable: Variable, body: Symbols) -> None:\n",
    "        self.mVariable: Variable = variable\n",
    "        self.mBody    : Symbols  = body\n",
    "        \n",
    "    def __eq__(self, other) -> bool:\n",
    "        return isinstance(other, GrammarRule)    and \\\n",
    "               self.mVariable == other.mVariable and \\\n",
    "               self.mBody     == other.mBody\n",
    "    \n",
    "    def __ne__(self, other) -> bool:\n",
    "        return not self.__eq__(other)\n",
    "    \n",
    "    def __hash__(self) -> int:\n",
    "        return hash(self.__repr__())\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.mVariable} → {\" \".join(self.mBody)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `transform(rules)` takes a list of tuples representing grammar rules and converts these tuples into objects of class \n",
    "`GrammarRule`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(rules: list[tuple[Symbol, ...]]) -> list[GrammarRule]:\n",
    "    return [ GrammarRule(var, tuple(body)) for (var, *body) in rules]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruleList: list[tuple[Symbol, ...]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = transform(ruleList) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a string `name`, which is either a *variable*, a *token*, or a *literal*, the function `is_var` checks whether `name` is a variable.  The function can distinguish variable names from tokens and literals because variable names consist only of lower case letters, while tokens are all uppercase and literals start with the character \"`'`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_var(name: Symbol) -> bool:\n",
    "    return name[0].islower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a list `Rules` of `GrammarRules`, the function `collect_variables(Rules)` returns the set of all *variables* occuring in `Rules`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_variables(Rules: list[GrammarRule]) -> set[Variable]:\n",
    "    Variables: set[Variable] = set()\n",
    "    for rule in Rules:\n",
    "        print(rule)\n",
    "        Variables.add(rule.mVariable)\n",
    "        for item in rule.mBody:\n",
    "            if is_var(item):\n",
    "                Variables.add(item)\n",
    "    return Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_variables(grammar) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a set `Rules` of `GrammarRules`, the function `collect_tokens(Rules)` returns the set of all *tokens* and *literals* occuring in `Rules`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_tokens(Rules: list[GrammarRule]) -> set[Token]:\n",
    "    Tokens: set[Token] = set()\n",
    "    for rule in Rules:\n",
    "        for item in rule.mBody:\n",
    "            if not is_var(item):\n",
    "                Tokens.add(item)\n",
    "    return Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_tokens(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marked Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `MarkedRule` stores a single *marked rule* of the form\n",
    "$$ v \\rightarrow \\alpha \\bullet \\beta $$\n",
    "where the *variable* $v$ is stored in the member variable `mVariable`, while $\\alpha$ and $\\beta$ are stored in the variables `mAlpha`and `mBeta` respectively.  These variables are assumed to contain tuples of *grammar symbols*.  A *grammar symbol* is either\n",
    "- a *variable*,\n",
    "- a *token*, or\n",
    "- a *literal*, i.e. a string enclosed in single quotes.\n",
    "\n",
    "\n",
    "Later, we need to maintain sets of *marked rules* to represent *states*.  Therefore, we have to define the methods `__eq__`, `__ne__`, and `__hash__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkedRule():\n",
    "    def __init__(self, variable: Variable, alpha: Symbols, beta: Symbols) -> None:\n",
    "        self.mVariable: Variable = variable\n",
    "        self.mAlpha   : Symbols  = alpha\n",
    "        self.mBeta    : Symbols  = beta\n",
    "        \n",
    "    def __eq__(self, other) -> bool:\n",
    "        return isinstance(other, MarkedRule)     and \\\n",
    "               self.mVariable == other.mVariable and \\\n",
    "               self.mAlpha    == other.mAlpha    and \\\n",
    "               self.mBeta     == other.mBeta\n",
    "    \n",
    "    def __ne__(self, other) -> bool:\n",
    "        return not self.__eq__(other)\n",
    "    \n",
    "    def __hash__(self) -> int:\n",
    "        return hash(self.__repr__())\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        alphaStr = ' '.join(self.mAlpha)\n",
    "        betaStr  = ' '.join(self.mBeta)\n",
    "        return f'{self.mVariable} → {alphaStr} • {betaStr}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a *marked rule* `self`, the function `is_complete` checks, whether the *marked rule* `self` has the form\n",
    "$$ c \\rightarrow \\alpha\\; \\bullet,$$\n",
    "i.e. it checks, whether the $\\bullet$ is at the end of the grammar rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_complete(self: MarkedRule) -> bool:\n",
    "    return len(self.mBeta) == 0\n",
    "\n",
    "MarkedRule.is_complete = is_complete # type: ignore\n",
    "del is_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a *marked rule* `self` of the form\n",
    "$$ c \\rightarrow \\alpha \\bullet X\\, \\delta, $$\n",
    "the function `symbol_after_dot` returns the *symbol* $X$. If there is no symbol after the $\\bullet$, the method returns `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbol_after_dot(self: MarkedRule) -> Symbol | None:\n",
    "    if len(self.mBeta) > 0:\n",
    "        return self.mBeta[0]\n",
    "    return None\n",
    "\n",
    "MarkedRule.symbol_after_dot = symbol_after_dot # type: ignore\n",
    "del symbol_after_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a marked rule of the form\n",
    "$$ c \\rightarrow \\alpha \\bullet b \\delta, $$\n",
    "this function returns the variable $b$ following the dot.  If there is no variable following the dot, the function returns `None`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_var(self: MarkedRule) -> Variable | None:\n",
    "    if len(self.mBeta) > 0:\n",
    "        var = self.mBeta[0]\n",
    "        if is_var(var):\n",
    "            return var\n",
    "    return None\n",
    "\n",
    "MarkedRule.next_var = next_var # type: ignore\n",
    "del next_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `move_dot(self)` transforms a *marked rule*  of the form \n",
    "$$ c \\rightarrow \\alpha \\bullet X\\, \\beta $$\n",
    "into a *marked rule* of the form\n",
    "$$ c \\rightarrow \\alpha\\, X \\bullet \\beta, $$\n",
    "i.e. the $\\bullet$ is moved over the next symbol.  Invocation of this method assumes that there is a symbol\n",
    "following the $\\bullet$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_dot(self: MarkedRule) -> MarkedRule:\n",
    "    return MarkedRule(self.mVariable, \n",
    "                      self.mAlpha + (self.mBeta[0],), \n",
    "                      self.mBeta[1:])\n",
    "\n",
    "MarkedRule.move_dot = move_dot # type: ignore\n",
    "del move_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `to_rule(self)` turns the *marked rule* `self` into  a `GrammarRule`, i.e. the *marked rule*\n",
    "$$ c \\rightarrow \\alpha \\bullet \\beta $$\n",
    "is turned into the grammar rule\n",
    "$$ c \\rightarrow \\alpha\\, \\beta. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rule(self: MarkedRule) -> GrammarRule:\n",
    "    return GrammarRule(self.mVariable, self.mAlpha + self.mBeta)\n",
    "\n",
    "MarkedRule.to_rule = to_rule # type: ignore\n",
    "del to_rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLR-Table-Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `Grammar` represents a context free grammar.  It stores a list of the `GrammarRules` of the given grammar.\n",
    "Each grammar rule is of the form\n",
    "$$ a \\rightarrow \\beta $$\n",
    "where $\\beta$ is a tuple of variables, tokens, and literals.\n",
    "The start symbol is assumed to be the variable on the left hand side of the first rule. The grammar is *augmented* with the rule\n",
    "$$ \\widehat{s} \\rightarrow s\\, \\$. $$\n",
    "Here $s$ is the start variable of the given grammar and $\\widehat{s}$ is a new variable that is the start variable of the *augmented grammar*. The symbol `$` denotes the end of input.  The non-obvious member variables of the class `Grammar` have the following interpretation\n",
    "- `mStates` is the set of all states of the *SLR-parser*.  These states are sets of *marked rules*.\n",
    "- `mStateNames`is a dictionary assigning names of the form `s0`, `s1`, $\\cdots$, `sn` to the states stored in \n",
    "  `mStates`.  The functions `action` and `goto` will be defined for *state names*, not for *states*, because \n",
    "  otherwise the table representing these functions would become both huge and unreadable.\n",
    "  Therefore, the dictionary `mStateNames` is needed to associate the the states with their names.\n",
    "- `mConflicts` is a Boolean variable that will be set to `True` if the table generation discovers \n",
    "  *shift/reduce conflicts* or *reduce/reduce conflicts*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grammar():\n",
    "    def __init__(self, Rules: list[GrammarRule]):\n",
    "        self.mRules     : list[GrammarRule] = Rules\n",
    "        self.mStart     : Variable          = Rules[0].mVariable\n",
    "        self.mVariables : set[Variable]     = collect_variables(Rules)\n",
    "        self.mTokens    : set[Token]        = collect_tokens(Rules)\n",
    "        self.mStates    : set[frozenset[MarkedRule]] = set()\n",
    "        self.mConflicts : bool              = False\n",
    "        self.mStateNames: dict[str, set[MarkedRule]] = {}\n",
    "        self.mVariables.add('ŝ')\n",
    "        self.mTokens.add('$') # short for EOF\n",
    "        self.mRules.append(GrammarRule('ŝ', (self.mStart, '$'))) # augment the grammar\n",
    "        self.mRuleNames: dict[GrammarRule, str] = {} \n",
    "        self.compute_tables()                                    \n",
    "\n",
    "    def compute_tables(self) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a set of `Variables`, the function `initialize_dictionary` returns a dictionary that assigns the empty set to all variables.\n",
    "This function is needed to initialize the member variable `mFirst` and `mFollow` that are dictionaries storing the *first-set* and\n",
    "*follow-sets* of the syntactical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_dictionary(Variables: set[Variable]) -> dict[Variable, set[Token]]:\n",
    "    return { a: set() for a in Variables }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a `Grammar`, the function `compute_tables` computes\n",
    "- the sets `First(v)` and `Follow(v)` for every variable `v`,\n",
    "- the set of all *states* of the *SLR-Parser*,\n",
    "- the *action table*, and\n",
    "- the *goto table*. \n",
    "\n",
    "Given a grammar `g`,\n",
    "- the set `g.mFirst` is a dictionary such that `g.mFirst[a] = First(a)` and\n",
    "- the set `g.mFollow` is a dictionary such that `g.mFollow[a] = Follow(a)` for all variables `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tables(self: Grammar) -> None:\n",
    "    self.mFirst  = initialize_dictionary(self.mVariables) # type: ignore\n",
    "    self.mFollow = initialize_dictionary(self.mVariables) # type: ignore\n",
    "    self.compute_first()         # type: ignore\n",
    "    self.compute_follow()        # type: ignore\n",
    "    self.compute_rule_names()    # type: ignore\n",
    "    self.all_states()            # type: ignore\n",
    "    self.compute_action_table()  # type: ignore\n",
    "    self.compute_goto_table()    # type: ignore\n",
    "    \n",
    "Grammar.compute_tables = compute_tables # type: ignore\n",
    "del compute_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `compute_rule_names` assigns a unique name to each *rule* of the grammar.  These names are used later\n",
    "to represent *reduce actions* in the *action table*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rule_names(self: Grammar) -> None:\n",
    "    counter = 0\n",
    "    for rule in self.mRules:\n",
    "        self.mRuleNames[rule] = 'r' + str(counter)\n",
    "        counter += 1\n",
    "        \n",
    "Grammar.compute_rule_names = compute_rule_names # type: ignore\n",
    "del compute_rule_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `compute_first(self)` computes the sets $\\texttt{First}(c)$ for all variables $c$ and stores them in the dictionary `mFirst`.  Abstractly, given a variable $c$ the function $\\texttt{First}(c)$ is the set of all tokens that can start a string that is derived from $c$:\n",
    "$$\\texttt{First}(\\texttt{c}) := \n",
    "  \\Bigl\\{ t \\in T \\Bigm| \\exists \\gamma \\in (V \\cup T)^*: \\texttt{c} \\Rightarrow^* t\\,\\gamma \\Bigr\\}.\n",
    "$$\n",
    "The definition of the function $\\texttt{First}()$ is extended to strings from $(V \\cup T)^*$ as follows:\n",
    "- $\\texttt{FirstList}(\\lambda) = \\{\\}$.\n",
    "- $\\texttt{FirstList}(t \\beta) = \\{ t \\}$  if $t \\in T$.\n",
    "- $\\texttt{FirstList}(\\texttt{a} \\beta) = \\left\\{\n",
    "       \\begin{array}[c]{ll}\n",
    "         \\texttt{First}(\\texttt{a}) \\cup \\texttt{FirstList}(\\beta) & \\mbox{if $\\texttt{a} \\Rightarrow^* \\lambda$;} \\\\\n",
    "         \\texttt{First}(\\texttt{a})                                & \\mbox{otherwise.}\n",
    "       \\end{array}\n",
    "       \\right.\n",
    "      $ \n",
    "\n",
    "If $\\texttt{a}$ is a variable of $G$ and the rules defining $\\texttt{a}$ are given as \n",
    "$$\\texttt{a} \\rightarrow \\alpha_1 \\mid \\cdots \\mid \\alpha_n, $$\n",
    "then we have\n",
    "$$\\texttt{First}(\\texttt{a}) = \\bigcup\\limits_{i=1}^n \\texttt{FirstList}(\\alpha_i). $$\n",
    "The dictionary `mFirst` that stores this function is computed via a *fixed point iteration*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_first(self: Grammar) -> None:\n",
    "    change = True\n",
    "    while change:\n",
    "        change = False\n",
    "        for rule in self.mRules:\n",
    "            a, body = rule.mVariable, rule.mBody\n",
    "            first_body = self.first_list(body)      # type: ignore\n",
    "            if not (first_body <= self.mFirst[a]):  # type: ignore\n",
    "                change = True\n",
    "                self.mFirst[a] |= first_body        # type: ignore   \n",
    "    print('First sets:')\n",
    "    for v in self.mVariables:\n",
    "        print(f'First({v}) = {self.mFirst[v]}')     # type: ignore\n",
    "        \n",
    "Grammar.compute_first = compute_first               # type: ignore\n",
    "del compute_first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a tuple of variables and tokens `alpha`, the function `first_list(alpha)` computes the function $\\texttt{FirstList}(\\alpha)$ that has been defined above.  If `alpha` is *nullable*, then the result will contain the empty string $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_list(self: Grammar, alpha: Symbols) -> set[Token]:\n",
    "    if len(alpha) == 0:\n",
    "        return { '' }\n",
    "    elif is_var(alpha[0]): \n",
    "        v, *r = alpha\n",
    "        return eps_union(self.mFirst[v], self.first_list(r)) # type: ignore\n",
    "    else:\n",
    "        t = alpha[0]\n",
    "        return { t }\n",
    "    \n",
    "Grammar.first_list = first_list                              # type: ignore\n",
    "del first_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arguments `S` and `T` of `eps_union` are sets that contain tokens and, additionally, they might contain the empty string \n",
    "$\\lambda =$ `''`.  The specification of `eps_union` is:\n",
    "$$ \\texttt{eps\\_union}(S, T) = \\left\\{ \\begin{array}{ll}\n",
    "                                       S          & \\mbox{if $\\lambda \\not\\in S$} \\\\\n",
    "                                       S \\cup T   & \\mbox{if $\\lambda \\in S \\wedge \\lambda \\in T$} \\\\\n",
    "                                       S \\cup T - \\{\\lambda \\} & \\mbox{if $\\lambda \\in S \\wedge \\lambda \\not\\in T$}\n",
    "                                      \\end{array}\n",
    "                              \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eps_union(S: set[Token], T: set[Token]) -> set[Token]:\n",
    "    if '' in S: \n",
    "        if '' in T: \n",
    "            return S | T\n",
    "        return (S - { '' }) | T\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an augmented grammar $G = \\langle V,T,R\\cup\\{\\widehat{s} \\rightarrow s\\,\\$\\}, \\widehat{s}\\rangle$ \n",
    "and a variable $a$, the set of tokens that might follow $a$ is defined as:\n",
    "$$\\texttt{Follow}(a) := \n",
    " \\bigl\\{ t \\in \\widehat{T} \\,\\bigm|\\, \\exists \\beta,\\gamma \\in (V \\cup \\widehat{T})^*: \n",
    "                           \\widehat{s} \\Rightarrow^* \\beta \\,a\\, t\\, \\gamma \n",
    "  \\bigr\\}.\n",
    "$$\n",
    "The function `compute_follow` computes the sets $\\texttt{Follow}(a)$ for all variables $a$ via a *fixed-point iteration*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_follow(self: Grammar) -> None:\n",
    "    self.mFollow[self.mStart] = { '$' }                           # type: ignore\n",
    "    change = True\n",
    "    while change:\n",
    "        change = False\n",
    "        for rule in self.mRules:\n",
    "            a, body = rule.mVariable, rule.mBody\n",
    "            for i in range(len(body)):\n",
    "                if is_var(body[i]):\n",
    "                    yi        = body[i]\n",
    "                    Tail      = self.first_list(body[i+1:])       # type: ignore\n",
    "                    firstTail = eps_union(Tail, self.mFollow[a])  # type: ignore\n",
    "                    if not (firstTail <= self.mFollow[yi]):       # type: ignore\n",
    "                        change = True\n",
    "                        self.mFollow[yi] |= firstTail             # type: ignore\n",
    "    print('Follow sets (note that \"$\" denotes the end of file):')\n",
    "    for v in self.mVariables:\n",
    "        print(f'Follow({v}) = {self.mFollow[v]}')                 # type: ignore\n",
    "        \n",
    "Grammar.compute_follow = compute_follow                           # type: ignore\n",
    "del compute_follow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\mathcal{M}$ is a set of *marked rules*, then the *closure* of $\\mathcal{M}$ is the smallest set $\\mathcal{K}$ such that\n",
    "we have the following:\n",
    "- $\\mathcal{M} \\subseteq \\mathcal{K}$,\n",
    "- If $a \\rightarrow \\beta \\bullet c\\, \\delta$ is a *marked rule* from \n",
    "  $\\mathcal{K}$, and $c$ is a variable and if, furthermore,\n",
    "  $c \\rightarrow \\gamma$ is a grammar rule,\n",
    "  then the marked rule $c \\rightarrow \\bullet \\gamma$\n",
    "  is an element of $\\mathcal{K}$:\n",
    "  $$(a \\rightarrow \\beta \\bullet c\\, \\delta) \\in \\mathcal{K} \n",
    "         \\;\\wedge\\; \n",
    "         (c \\rightarrow \\gamma) \\in R\n",
    "         \\;\\Rightarrow\\; (c \\rightarrow \\bullet \\gamma) \\in \\mathcal{K}\n",
    "  $$\n",
    "\n",
    "We define $\\texttt{closure}(\\mathcal{M}) := \\mathcal{K}$.  The function `cmp_closure` computes this closure for a given set of *marked rules* via a *fixed-point iteration*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp_closure(self, Marked_Rules: set[MarkedRule]) -> frozenset[MarkedRule]:\n",
    "    All_Rules = Marked_Rules\n",
    "    New_Rules = Marked_Rules\n",
    "    while True:\n",
    "        More_Rules = set()\n",
    "        for rule in New_Rules:\n",
    "            c = rule.next_var()                                  # type: ignore\n",
    "            if c == None:\n",
    "                continue\n",
    "            for rule in self.mRules:\n",
    "                head, alpha = rule.mVariable, rule.mBody         # type: ignore\n",
    "                if c == head:\n",
    "                    More_Rules |= { MarkedRule(head, (), alpha) }\n",
    "        if More_Rules <= All_Rules:\n",
    "            return frozenset(All_Rules)\n",
    "        New_Rules  = More_Rules - All_Rules\n",
    "        All_Rules |= New_Rules\n",
    "\n",
    "Grammar.cmp_closure = cmp_closure                                 # type: ignore\n",
    "del cmp_closure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a set of *marked rules* $\\mathcal{M}$ and a *grammar symbol* $X$, the function $\\texttt{goto}(\\mathcal{M}, X)$ \n",
    "is defined as follows:\n",
    "$$\\texttt{goto}(\\mathcal{M}, X) := \\texttt{closure}\\Bigl( \\bigl\\{ \n",
    "   a \\rightarrow \\beta\\, X \\bullet \\delta \\bigm| (a \\rightarrow \\beta \\bullet X\\, \\delta) \\in \\mathcal{M} \n",
    "   \\bigr\\} \\Bigr).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goto(self, Marked_Rules, x):\n",
    "    Result = set()\n",
    "    for mr in Marked_Rules:\n",
    "        if mr.symbol_after_dot() == x:\n",
    "            Result.add(mr.move_dot())\n",
    "    return self.cmp_closure(Result)\n",
    "\n",
    "Grammar.goto = goto  # type: ignore\n",
    "del goto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `all_states` computes the set of all states of an *SLR-parser*.  The function starts with the state\n",
    "$$ \\texttt{closure}\\bigl(\\{ \\widehat{s} \\rightarrow \\bullet s \\, $\\}\\bigr) $$\n",
    "and then tries to compute new states by using the function `goto`.  This computation proceeds via a \n",
    "*fixed-point iteration*.  Once all states have been computed, the function assigns names to these states.\n",
    "This association is stored in the dictionary *mStateNames*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_states(self) -> None: \n",
    "    start_state  = self.cmp_closure({ MarkedRule('ŝ', (), (self.mStart, '$')) })\n",
    "    self.mStates = { start_state }\n",
    "    New_States   = self.mStates\n",
    "    while True:\n",
    "        More_States = set()\n",
    "        for Rule_Set in New_States:\n",
    "            for mr in Rule_Set: \n",
    "                if not mr.is_complete():\n",
    "                    x = mr.symbol_after_dot()\n",
    "                    if x != '$':\n",
    "                        More_States |= { self.goto(Rule_Set, x) }\n",
    "        if More_States <= self.mStates:\n",
    "            break\n",
    "        New_States = More_States - self.mStates;\n",
    "        self.mStates |= New_States\n",
    "    print(\"All SLR-states:\")\n",
    "    counter = 1\n",
    "    self.mStateNames[start_state] = 's0'\n",
    "    print(f's0 = {set(start_state)}')\n",
    "    for state in self.mStates - { start_state }:\n",
    "        self.mStateNames[state] = f's{counter}'\n",
    "        print(f's{counter} = {set(state)}')\n",
    "        counter += 1\n",
    "\n",
    "Grammar.all_states = all_states # type: ignore\n",
    "del all_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function computes the *action table* and is defined as follows:\n",
    "- If $\\mathcal{M}$ contains a *marked rule* of the form $a \\rightarrow \\beta \\bullet t\\, \\delta$\n",
    "  then we have\n",
    "  $$\\texttt{action}(\\mathcal{M},t) := \\langle \\texttt{shift}, \\texttt{goto}(\\mathcal{M},t) \\rangle.$$\n",
    "- If $\\mathcal{M}$ contains a marked rule of the form $a \\rightarrow \\beta\\, \\bullet$ and we have\n",
    "  $t \\in \\texttt{Follow}(a)$, then we define\n",
    "  $$\\texttt{action}(\\mathcal{M},t) := \\langle \\texttt{reduce}, a \\rightarrow \\beta \\rangle$$\n",
    "- If $\\mathcal{M}$ contains the marked rule $\\widehat{s} \\rightarrow s \\bullet \\$ $, then we define \n",
    "  $$\\texttt{action}(\\mathcal{M},\\$) := \\texttt{accept}. $$\n",
    "- Otherwise, we have\n",
    "  $$\\texttt{action}(\\mathcal{M},t) := \\texttt{error}. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_action_table(self):\n",
    "    self.mActionTable = {}\n",
    "    print('\\nAction Table:')\n",
    "    for state in self.mStates:\n",
    "        stateName = self.mStateNames[state]\n",
    "        actionTable = {}\n",
    "        # compute shift actions\n",
    "        for token in self.mTokens:\n",
    "            if token != '$':\n",
    "                newState  = self.goto(state, token)\n",
    "                if newState != set():\n",
    "                    newName = self.mStateNames[newState]\n",
    "                    actionTable[token] = ('shift', newName)\n",
    "                    self.mActionTable[stateName, token] = ('shift', newName)\n",
    "                    print(f'action(\"{stateName}\", {token}) = (\"shift\", {newName})')\n",
    "        # compute reduce actions\n",
    "        for mr in state:\n",
    "            if mr.is_complete():\n",
    "                for token in self.mFollow[mr.mVariable]:\n",
    "                    action1 = actionTable.get(token)\n",
    "                    action2 = ('reduce', mr.to_rule())\n",
    "                    if action1 == None:\n",
    "                        actionTable[token] = action2  \n",
    "                        r = self.mRuleNames[mr.to_rule()]\n",
    "                        self.mActionTable[stateName, token] = ('reduce', r)\n",
    "                        print(f'action(\"{stateName}\", {token}) = {action2}')\n",
    "                    elif action1 != action2: \n",
    "                        self.mConflicts = True\n",
    "                        print('')\n",
    "                        print(f'conflict in state {stateName}:')\n",
    "                        print(f'{stateName} = {state}')\n",
    "                        print(f'action(\"{stateName}\", {token}) = {action1}')     \n",
    "                        print(f'action(\"{stateName}\", {token}) = {action2}')\n",
    "                        print('')\n",
    "        for mr in state:\n",
    "            if mr == MarkedRule('ŝ', (self.mStart,), ('$',)):\n",
    "                actionTable['$'] = 'accept'\n",
    "                self.mActionTable[stateName, '$'] = 'accept'\n",
    "                print(f'action(\"{stateName}\", $) = accept')\n",
    "\n",
    "Grammar.compute_action_table = compute_action_table # type: ignore\n",
    "del compute_action_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `compute_goto_table` computes the *goto table*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_goto_table(self) -> None:\n",
    "    self.mGotoTable = {}\n",
    "    print('\\nGoto Table:')\n",
    "    for state in self.mStates:\n",
    "        for var in self.mVariables:\n",
    "            newState = self.goto(state, var)\n",
    "            if newState != set():\n",
    "                stateName = self.mStateNames[state]\n",
    "                newName   = self.mStateNames[newState]\n",
    "                self.mGotoTable[stateName, var] = newName\n",
    "                print(f'goto({stateName}, {var}) = {newName}')\n",
    "\n",
    "Grammar.compute_goto_table = compute_goto_table # type: ignore\n",
    "del compute_goto_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "g = Grammar(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_quotes(t):\n",
    "    if t[0] == \"'\" and t[-1] == \"'\":\n",
    "        return t[1:-1]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_parse_table(self, file: str) -> None:\n",
    "    with open(file, 'w', encoding=\"utf-8\") as handle:\n",
    "        handle.write('# Grammar rules:\\n')\n",
    "        for rule in self.mRules:\n",
    "            rule_name = self.mRuleNames[rule] \n",
    "            handle.write(f'{rule_name} = (\"{rule.mVariable}\", {rule.mBody})\\n')\n",
    "        handle.write('\\n# Action table:\\n')\n",
    "        handle.write('actionTable = {}\\n')\n",
    "        for s, t in self.mActionTable:\n",
    "            action = self.mActionTable[s, t]\n",
    "            t = strip_quotes(t)\n",
    "            if action[0] == 'reduce':\n",
    "                rule_name = action[1]\n",
    "                handle.write(f\"actionTable['{s}', '{t}'] = ('reduce', {rule_name})\\n\")\n",
    "            elif action == 'accept':\n",
    "                handle.write(f\"actionTable['{s}', '{t}'] = 'accept'\\n\")\n",
    "            else:\n",
    "                handle.write(f\"actionTable['{s}', '{t}'] = {action}\\n\")\n",
    "        handle.write('\\n# Goto table:\\n')\n",
    "        handle.write('gotoTable = {}\\n')\n",
    "        for s, v in self.mGotoTable:\n",
    "            state = self.mGotoTable[s, v]\n",
    "            handle.write(f\"gotoTable['{s}', '{v}'] = '{state}'\\n\")\n",
    "        \n",
    "Grammar.dump_parse_table = dump_parse_table # type: ignore\n",
    "del dump_parse_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.dump_parse_table('parse-table.py') # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat parse-table.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse(file):\n",
    "    rules        = parse(file)\n",
    "    grammarRules = transform(rules) \n",
    "    grammar      = Grammar(grammarRules)\n",
    "    grammar.dump_parse_table('parse-table.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse('Examples/arith-small.g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "analyse('Examples/arith-ambiguous.g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "analyse('Examples/c-grammar-slr.g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "analyse('Examples/c-grammar.g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse('Examples/bool.g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

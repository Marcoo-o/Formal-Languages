{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff392407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "with open (\"../style.css\", \"r\") as file:\n",
    "    css = file.read()\n",
    "HTML(css)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616b12a5",
   "metadata": {},
   "source": [
    "# A Simple Email Harvester"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c52c1",
   "metadata": {},
   "source": [
    "We will use three libraries:\n",
    "* `re` is the library for regular expressions.  \n",
    "   + `re.compile(r)` compiles a regular expression `r` into a\n",
    "     *finite state machine* that implements this regular expression.\n",
    "   + `o.findall(s)` takes a finite state machine `o` and \n",
    "     a string `s`.  It returns a list containing all substrings of `s`\n",
    "     that are matched by the regular expression that was compiled into `o`.\n",
    "   + `re.sub(o, t, s)` receives three arguments:\n",
    "     1. `o` is a finite state machine that is the result of compiling some \n",
    "        regular expression `r`.\n",
    "     2. `t` is a string.\n",
    "     3. `s` is a string.\n",
    "     \n",
    "     The function finds all substrings that are matched by `r` and replaces these substrings with `t`.\n",
    "     The resulting string is returned.\n",
    "* `requests` is used the send `HTTP` requests.\n",
    "\n",
    "  We will use this library to download webpages.  The function\n",
    "  ```\n",
    "  response = requests.get(url)\n",
    "  ```\n",
    "  is used to download a web page.  The text of this webpage can then be retrieved as\n",
    "  ```\n",
    "  page = response.text\n",
    "  ```\n",
    "* `urllib.parse`  defines functions to manipulate URLs and their components parts.\n",
    "  + `urljoin(base_url, relative_url)` combines `base_url` and `relative_url` into a url.\n",
    "  + `urlparse(url)` creates an object that has the attribute `netloc`.  This attribute can be used\n",
    "    to check the host that provides the given url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31566e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from urllib.parse import urljoin, urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c784f3",
   "metadata": {},
   "source": [
    "First, we compile some regular expressions into finite state machines and stores these FSMs\n",
    "in global variables.\n",
    "1. The regular expression `r'\\<span style=\"display: none;\"\\>[^<>]*\\</span\\>'`\n",
    "   is used because most email adresses are disguised as follows:\n",
    "   ```\n",
    "   karl.stroetmann<span style=\"display: none;\"> No Spam \\</span>@dhbw-mannheim.de`\n",
    "   ```\n",
    "   We have to remove the part `<span style=\"display: none;\"> No Spam \\</span>` from the web page\n",
    "   so that email adresses can be recognized.\n",
    "2. The regular expression `r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'` is used\n",
    "   to locate email addresses.\n",
    "3. The regular expression `r'<a [^>]*href=[\"\\'](.*?)[\"\\']'` is used\n",
    "   to locate hypertext links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b269b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "INVISIBLE = re.compile(r'\\<span style=\"display: none;\"\\>[^<>]*\\</span\\>')\n",
    "EMAIL     = re.compile(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}')\n",
    "LINK      = re.compile(r'<a [^>]*href=[\"\\'](.*?)[\"\\']')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b0a9ad",
   "metadata": {},
   "source": [
    "The function `retrieve_page(url)` retrieves the text of the web page at the given `url`.\n",
    "It also removes text like `<span style=\"display: none;\"\\> No Spam \\</span>` from this text.\n",
    "Text of this kind is sometimes inserted in email adresses to make it more difficult to\n",
    "harvest them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fda8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_page(url):\n",
    "    response = requests.get(url)     # make http request \n",
    "    page     = response.text         # retrieve webpage\n",
    "    return re.sub(INVISIBLE, '', page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e968cae9",
   "metadata": {},
   "source": [
    "The function `extract_emails(url)` takes a web address and tries to find all email adresses that occur on web pages\n",
    "that are reachable from `url`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08046ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emails(url): \n",
    "    Emails        = set()                # set to store unique Emails\n",
    "    ProcessedUrls = set()                # set to store unique processed URLs\n",
    "    URL_Stack = [ url ]                  # stack to manage URLs to be scraped\n",
    "    while URL_Stack:\n",
    "        url = URL_Stack.pop()\n",
    "        if url in ProcessedUrls:         # check if URL has already been processed\n",
    "            continue\n",
    "        ProcessedUrls.add(url)           # mark URL as processed\n",
    "        page = retrieve_page(url)\n",
    "        # extract Emails using regex\n",
    "        for mail in EMAIL.findall(page):\n",
    "            if mail not in Emails:\n",
    "                print(mail)\n",
    "                Emails.add(mail)\n",
    "        # extract links using regex\n",
    "        links = LINK.findall(page)\n",
    "        for link in links:  # find and process links to other pages on the same server\n",
    "            next_url = urljoin(url, link)\n",
    "            # check if the URL is on the same server\n",
    "            if urlparse(url).netloc == urlparse(next_url).netloc:\n",
    "                next_str = str(next_url)\n",
    "                endings  = { '.pdf', 'docx', '.png', '.jpg', 'xlsx', '.mp4' }\n",
    "                if '?' not in next_str and next_str[-4:] not in endings:\n",
    "                    URL_Stack.append(next_url)\n",
    "    return Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636725fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "url = 'https://dhbw-mannheim.de'\n",
    "emails = extract_emails(url)\n",
    "for email in emails:\n",
    "    print(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb250346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

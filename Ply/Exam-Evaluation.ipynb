{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style>\n",
    ".container { width: 100% }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating an Exam Using Ply\n",
    "\n",
    "This notebook shows how we can use the library [`ply`](https://ply.readthedocs.io/en/latest/ply.html)\n",
    "to implement a scanner.  Our goal is to implement a scanner that can be used to evaluate the results\n",
    "of an exam.  Assume the result of an exam is stored in the string `data` that is defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \\\n",
    "'''Class: Algorithms and Complexity\n",
    "   Group: TIT09AID\n",
    "   MaxPoints = 60\n",
    "   \n",
    "   Exercise:      1. 2. 3. 4. 5. 6.\n",
    "   Jim Smith:     9 12 10  6  6  0\n",
    "   John Slow:     4  4  2  0  -  -\n",
    "   Susi Sorglos:  9 12 12  9  9  6\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data show that there has been a exam with the subject <em style=\"color:blue\">Algorithms and Complexity</em>\n",
    "in the group <em style=\"color:blue\">TIT09AID</em>.  Furthermore, the data shows that in order to achieve\n",
    "100%, <em style=\"color:blue\">60</em> points would have been necessary.\n",
    "    \n",
    "There have been 6 different exercises in this exam and, in this small example,  only three students took part, namely *Jim Smith*, *John Slow*, and *Susi Sorglos*.  Each of the rows that contain the results that one student has achieved in this exam begins with the name of the student followed by the number of points that she has achieved in the different exercises. Our goal is to write a program that is able to compute the marks for all students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be use the library [ply](https://ply.readthedocs.io/en/latest/ply.html).\n",
    "In this example, we will only use the scanner that is provided by the module `ply.lex`. Hence we import this module from `ply`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ply.lex as lex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `mark(lexer)` takes the object `lexer` as its argument.  This object is supposed to be a scanner object that is generated by the expression `lex.lex()`.  This object provides two member variables:\n",
    "- `lexer.sum_points` is the number of points achieved by the student whose mark is to be computed.\n",
    "- `lexer.max_points` is the number of points that need to be achieved in order to get the best mark \n",
    "  of $1.0$.\n",
    "  \n",
    "It is assumed that the relation between the mark of an exam and the number of points achieved in this exam is linear and that a student who has achieved $50\\%$ of `lexer.max_points` points will get the mark $4.0$, while a student who has achieved  $100\\%$ of `lexer.max_points` points will be marked as $1.0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark(lexer):\n",
    "    return 7 - 6 * lexer.sum_points / lexer.max_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by defining the list of tokens.  Note that the variable `tokens` is a keyword of `ply` to define the names of the token classes.  In this case, we have declared six different tokens.\n",
    "- `HEADER` will match the first two lines of the string `data` as well as the fifth line that begins with \n",
    "  the substring `Exercise:`.  \n",
    "  \n",
    "  The precise definition of this token as well as the definition of the other token is given later.\n",
    "- `MAXDEF` is a token that will match the line `MaxPoints = 60`.\n",
    "- `NAME` is a token that will match the name of a student.\n",
    "- `NUMBER` is a token that will match a natural number.\n",
    "- `IGNORE` is a token that will match an empty line.  For example, the fourth line in `data` is empty.\n",
    "- `LINEBREAK` is a token that will match the newline character `\\n` at the end of a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [ 'HEADER',\n",
    "           'MAXDEF',\n",
    "           'NAME',\n",
    "           'NUMBER',\n",
    "           'IGNORE',\n",
    "           'LINEBREAK'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to provide the definition of the tokens.  One way to define tokens is via python functions.  The <em style=\"color:blue\">document string</em> of these functions is a <em style=\"color:blue\">raw string</em> that contains the regular expression defining the semantics of the token.  The regular expression can be followed by code that is needed to further process the token.  The name of the function defining a token has to have the form `t_`**name**, where **name** is the name of the token as declared in the list `tokens`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The token `HEADER` matches any string that is made up of upper and lower case characters followed by a colon.  The token extends to the end of the line and includes the terminating newline.\n",
    "\n",
    "When the function `t_HEADER` is called it is provided with a token `t`.  This is an object that has five\n",
    "attributes:\n",
    "- `t.lexer` is an object of class `Lexer` that contains the scanner that created this token `t`.\n",
    "  We are free to attach additional attributes to this object.\n",
    "- `t.type` is  a string containing the type of the token.  For tokens processed in the function\n",
    "  `t_HEADER` this type is always the string `HEADER`.\n",
    "- `t.value` is the actual string matched by the token.\n",
    "- `t.lineno` is the line number.  However, it is our responsibility to update this variable\n",
    "  by incrementing `t.lexer.lineno` every time we read a newline.\n",
    "- `t.lexpos` is the position of the token in input string that is scanned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_HEADER(t):\n",
    "    r'[A-Za-z]+:.*\\n'\n",
    "    t.lexer.lineno += 1\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The token `MAXDEF` matches a substring of the form `MaxPoints = 60`.  Note that the regular expression defining the semantics of this token uses the expression `\\s` to match the white space before and after the character `=`.  This is necessary because `ply.lex` uses verbose regular expressions that can contain whitespace for formatting.  Hence a blank character ` ` inside a regular expression is silently discarded.\n",
    "\n",
    "After defining the regular expression, the function `t_MAXDEF` has some <em style=\"color:blue\">action code</em> that is used to extract the maximal number of points form the token value and store this number in the variable `t.lexer.name`.  Furthermore, we initialize the student name to the empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_MAXDEF(t):\n",
    "    r'MaxPoints\\s=\\s[1-9][0-9]*'\n",
    "    t.lexer.max_points = int(t.value[12:])\n",
    "    t.lexer.name       = ''\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The token `NAME` matches the name of a student followed by a colon.  In general, a student name can be any sequence of letters that contain optional hypens and blanks. We have to reset the sum of points that is stored in `lexer.sum_points`to `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_NAME(t):\n",
    "    r'[a-zA-Z- ]+:'\n",
    "    t.lexer.name = t.value[:-1]\n",
    "    t.lexer.sum_points = 0\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The token `NUMBER`matches a natural number.  We have to convert the value, which initially is a string of digits, into an integer.  Furthermore, this value is the added to the number of point the current student has achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_NUMBER(t):\n",
    "    r'0|[1-9][0-9]*'\n",
    "    t.value = int(t.value)\n",
    "    t.lexer.sum_points += t.value\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The token `IGNORE` matches a line that contains only whitespace.  In order to keep track of line numbers we have to increment `lexer.lineno`.  However, we do not return a token at the end of the function.  Hence, an empty line is silently discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_IGNORE(t):\n",
    "    r'^[\\s\\t]*\\n'\n",
    "    t.lexer.lineno += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The token `LINEBREAK` matches a newlince character `\\n`.  If a student name is defined, then we output the result for this student.  Note that we set `lexer.name` back to the empty string once we have processed the student.\n",
    "This allows for empty lines between different students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_LINEBREAK(t):\n",
    "    r'\\n'\n",
    "    t.lexer.lineno += 1\n",
    "    if t.lexer.name != '':\n",
    "        print(f'{t.lexer.name} has {t.lexer.sum_points} points and the mark {round(mark(t.lexer), 2)}.')\n",
    "    t.lexer.name = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The string `t_ignore` specifies those characters that should be ignored.  Note that this string is **not** interpreted as a regular expression.  It is just a a string of <em style=\"color:blue\">single characters</em>.  These characters are allowed to occur as part of other tokens, but when they occur on their own and would otherwise generate a scanning error, they are silently discarded instead of triggering an error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ignore  = '- \\t'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `t_error` is called when a substring at the beginning of the input can not be matched by any of the regular expressions defined in the various tokens.  In our implementation we print the first character that could not be matched, discard this character and continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_error(t):\n",
    "    print(f\"Illegal character '{t.value[0]}'\")\n",
    "    t.lexer.skip(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line below is necessary to trick `ply.lex` into assuming this program is written in an ordiary python file instead of a *Jupyter notebook*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = 'main'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line below generates the scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexer = lex.lex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we feed an input string into the generated scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexer.input(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to scan the data that we provided in the last line, we iterate over all tokens generated by our scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan(lexer):\n",
    "    for t in lexer:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jim Smith has 43 points and the mark 2.7.\n",
      "John Slow has 10 points and the mark 6.0.\n",
      "Susi Sorglos has 57 points and the mark 1.3.\n"
     ]
    }
   ],
   "source": [
    "scan(lexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

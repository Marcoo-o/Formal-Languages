{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style>\n",
    ".container { width: 100% }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting <span style=\"font-variant:small-caps;\">Html</span> to Text\n",
    "\n",
    "This notebook shows how we can use the library [`ply`](https://ply.readthedocs.io/en/latest/ply.html)\n",
    "to extract the text that is embedded in an <span style=\"font-variant:small-caps;\">Html</span> file.  \n",
    "In order to be concise, it does only support a small subset of \n",
    "<span style=\"font-variant:small-caps;\">Html</span>.  Below is the content of my old\n",
    "<a href=\"http://wwwlehre.dhbw-stuttgart.de/~stroetma/\">web page</a> that I had used when I still \n",
    "worked at the DHBW Stuttgart.  The goal of this notebook is to write a scanner that is able to extract \n",
    "the text from this web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \\\n",
    "'''\n",
    "<html>\n",
    "  <head>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <title>Homepage of Prof. Dr. Karl Stroetmann</title>\n",
    "    <link type=\"text/css\" rel=\"stylesheet\" href=\"style.css\" />\n",
    "    <link href=\"http://fonts.googleapis.com/css?family=Rochester&subset=latin,latin-ext\"\n",
    "          rel=\"stylesheet\" type=\"text/css\">\n",
    "    <link href=\"http://fonts.googleapis.com/css?family=Pacifico&subset=latin,latin-ext\"\n",
    "          rel=\"stylesheet\" type=\"text/css\">\n",
    "    <link href=\"http://fonts.googleapis.com/css?family=Cabin+Sketch&subset=latin,latin-ext\" rel=\"stylesheet\" type=\"text/css\">\n",
    "    <link href=\"http://fonts.googleapis.com/css?family=Sacramento\" rel=\"stylesheet\" type=\"text/css\">\n",
    "  </head>\n",
    "  <body>\n",
    "    <hr/>\n",
    "\n",
    "    <div id=\"table\">\n",
    "      <header>\n",
    "        <h1 id=\"name\">Prof. Dr. Karl Stroetmann</h1>\n",
    "      </header>\n",
    "\n",
    "      <div id=\"row1\">\n",
    "        <div class=\"right\">\n",
    "          <a id=\"dhbw\" href=\"http://www.ba-stuttgart.de\">Duale Hochschule Baden-W&uuml;rttemberg</a>\n",
    "          <br/>Coblitzallee 1-9\n",
    "          <br/>68163 Mannheim\n",
    "          <br/>Germany\n",
    "\t  <br>\n",
    "          <br/>Office: &nbsp;&nbsp;&nbsp; Raum 344B\n",
    "          <br/>Phone:&nbsp;&nbsp;&nbsp; +49 621 4105-1376\n",
    "          <br/>Fax:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; +49 621 4105-1194\n",
    "          <br/>Skype: &nbsp;&nbsp;&nbsp; karlstroetmann\n",
    "        </div>  \n",
    "\n",
    "\n",
    "        <div id=\"links\">\n",
    "          <strong class=\"some\">Some links:</strong>\n",
    "          <ul class=\"inlink\">\n",
    "            <li class=\"inlink\">\n",
    "\t      My <a class=\"inlink\" href=\"https://github.com/karlstroetmann?tab=repositories\">lecture notes</a>,\n",
    "              as well as the programs presented in class, can be found\n",
    "              at <br>\n",
    "              <a class=\"inlink\" href=\"https://github.com/karlstroetmann?tab=repositories\">https://github.com/karlstroetmann</a>.\n",
    "              \n",
    "            </li>\n",
    "            <li class=\"inlink\">Most of my papers can be found at <a class=\"inlink\" href=\"https://www.researchgate.net/\">researchgate.net</a>.</li>\n",
    "            <li class=\"inlink\">The programming language SetlX can be downloaded at <br>\n",
    "              <a href=\"http://randoom.org/Software/SetlX\"><tt class=\"inlink\">http://randoom.org/Software/SetlX</tt></a>.\n",
    "            </li>\n",
    "          </ul>\n",
    "        </div>\n",
    "      </div>\n",
    "    </div>\n",
    "    \n",
    "    <div id=\"intro\">\n",
    "      As I am getting old and wise, I have to accept the limits of\n",
    "      my own capabilities.  I have condensed these deep philosophical\n",
    "      insights into a most beautiful pearl of poetry.  I would like \n",
    "      to share these humble words of wisdom:\n",
    "      \n",
    "      <div class=\"poetry\">\n",
    "        I am a teacher by profession,    <br>\n",
    "        mostly really by obsession;      <br>\n",
    "        But even though I boldly try,    <br>\n",
    "        I just cannot teach <a href=\"http://img1.wikia.nocookie.net/__cb20070831020747/uncyclopedia/images/a/a2/Flying_Pig.jpg\" id=\"fp\">pigs</a> to fly.</br>\n",
    "        Instead, I slaughter them and fry.\n",
    "      </div>\n",
    "      \n",
    "      <div class=\"citation\">\n",
    "        <div class=\"quote\">\n",
    "          Any sufficiently advanced poetry is indistinguishable from divine wisdom.\n",
    "        </div>\n",
    "        <div id=\"sign\">His holiness Pope Hugo &#8555;.</div>\n",
    "      </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be use the library [ply](https://ply.readthedocs.io/en/latest/ply.html) to extract the text that\n",
    "is embedded in the <span style=\"font-variant:small-caps;\">Html</span> shown above.\n",
    "In this example, we will only use the scanner that is provided by the module `ply.lex`. \n",
    "Hence we import the module `ply.lex` that contains the scanner generator from `ply`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ply.lex as lex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by defining the list of tokens.  Note that the variable `tokens` is a keyword of `ply` to define the names of the token classes.  In this case, we have declared nine different tokens.\n",
    "- `HEAD_START` will match the tag `<head>` that starts the definition of the \n",
    "  <span style=\"font-variant:small-caps;\">Html</span> header.\n",
    "- `HEAD_END` will match the tag `</head>` that ends the definition of the \n",
    "  <span style=\"font-variant:small-caps;\">Html</span> header.\n",
    "- `SCRIPT_START` will match the tag `<script>` that starts embedded *javascript* code.\n",
    "- `SCRIPT_END` will match the tag `</script>` that ends embedded *javascript* code.\n",
    "- `TAG` is a token that represents arbitrary <span style=\"font-variant:small-caps;\">Html</span> tags.\n",
    "- `LINEBREAK` is a token that will match the newline character `\\n` at the end of a line.\n",
    "- `NAMED_ENTITY` is a token that represents named <span style=\"font-variant:small-caps;\">Html5</span>\n",
    "  entities.\n",
    "- `UNICODE` is a token that represents a unicode entity.\n",
    "- `ANY` is a token that matches any character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [ 'HEAD_START',\n",
    "           'HEAD_END'\n",
    "           'SCRIPT_START',\n",
    "           'SCRIPT_END',\n",
    "           'TAG',\n",
    "           'LINEBREAK', \n",
    "           'NAMED_ENTITY',\n",
    "           'UNICODE',\n",
    "           'ANY'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are inside an <span style=\"font-variant:small-caps;\">Html</span> header or inside of some\n",
    "*javascript* code the rules of the scanning game change.  Therefore, we declare two new *exclusive* states:\n",
    "- `header` is the state the scanner is in while it is scanning an \n",
    "  <span style=\"font-variant:small-caps;\">Html</span> header.\n",
    "- `script` is the state of the scanner while scanning *javascript*.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [ ('header', 'exclusive'),\n",
    "           ('script', 'exclusive')\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed to define the definition of the tokens.  Note that none of the function defined below\n",
    "returns a token.  Rather all of these function print the transformation of the \n",
    "<span style=\"font-variant:small-caps;\">Html</span> that they have matched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the scanner reads the opening tag `<head>` it switches into the state `header`.  In this state it will continue to read and discard characters until it sees the closing tag `/head>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_HEAD_START(t):\n",
    "    r'<head>'\n",
    "    t.lexer.begin('header')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the scanner reads the opening tag `<script>` it switches into the state `script`.  In this state it will continue to read and discard characters until it sees the closing tag `/script>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_SCRIPT_START(t):\n",
    "    r'<script[^>]+>'\n",
    "    t.lexer.begin('script')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groups of newline characters are condensed into a single newline character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_LINEBREAK(t):\n",
    "    r'\\n+'\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The token `TAG` is defined as any string that starts with the character `<` and ends with the character \n",
    "`>`. Betweens these two characters there has to be a nonzero number of characters that are different from \n",
    "the character `>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_TAG(t):\n",
    "    r'<[^>]+>'\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to support named <span style=\"font-variant:small-caps;\">Html</span> entities we need to import\n",
    "the dictionary `html5` from the module `html.entities`.  For every named \n",
    "<span style=\"font-variant:small-caps;\">Html</span> entity `e`, `html[e]` is the unicode symbol that is specified by `e`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.entities import html5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html5['auml']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expresion `&[a-zA-Z]+;?` searches for <span style=\"font-variant:small-caps;\">Html</span>\n",
    "entity names.  These are strings that start with the character `&` followed by the name of the entity, optionally followed by the character `;`.  Then the unicode character corresponding to the name is looked up and printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_NAMED_ENTITY(t):\n",
    "    r'&[a-zA-Z]+;?'\n",
    "    if t.value[-1] == '?':\n",
    "        entity_name = t.value[1:-1]\n",
    "    else:\n",
    "        entity_name = t.value[1:]\n",
    "    unicode_char = html5[entity_name]\n",
    "    print(unicode_char, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expression `&\\#[0-9]+` searches for <span style=\"font-variant:small-caps;\">Html</span> entities that specify a unicode cahracter numerically.  The corresponding strings start with the character `&`\n",
    "followed by the character `#` followed by digits and ended with the character `;`.\n",
    "\n",
    "Note that we had to escape the character `#` with a  backslash because otherwise this character would signal the begin of a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_UNICODE(t):\n",
    "    r'&\\#[0-9]+;'\n",
    "    print(chr(int(t.value[2:-1])), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expression `.` matches any character that is different from a newline character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_ANY(t):\n",
    "    r'.'\n",
    "    print(t.value, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expression `</head>` matches the closing head tag.  Note that is regular expression is only\n",
    "active in state `header` as the name of this function starts with `t_header`.  Once the closing tag has been found, the function `lexer.begin` switches the lexer back into the state `INITIAL`, which is the \n",
    "start state of the scanner.  In this state, all token definitions are active, that do not start with \n",
    "either `t_header` or `t_script`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_header_HEAD_END(t):\n",
    "    r'</head>'\n",
    "    t.lexer.begin('INITIAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the scanner is either in the state `header` or the state `script`, the function \n",
    "`t_header_script_ANY` eats all characters without echoing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_header_script_ANY(t):\n",
    "    r'.|\\n'\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expression `</script>` matches the closing script tag.  Note that is regular expression is only\n",
    "active in state `script`.  Once the closing tag has been found, the function `lexer.begin` switches the lexer back into the state `INITIAL`, which is the \n",
    "start state of the scanner.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_script_SCRIPT_END(t):\n",
    "    r'</script>'\n",
    "    t.lexer.begin('INITIAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `t_error` is called when a substring at the beginning of the input can not be matched by any of the regular expressions defined in the various tokens.  In our implementation we print the first character that could not be matched, discard this character and continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_error(t):\n",
    "    print(f\"Illegal character: '{t.value[0]}'\")\n",
    "    t.lexer.skip(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `t_header_error` is called when a substring at the beginning of the input can not be matched by any of the regular expressions defined in the various tokens and the scanner is in state `header`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_header_error(t):\n",
    "    print(f\"Illegal character in state 'header': '{t.value[0]}'\")\n",
    "    t.lexer.skip(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `t_script_error` is called when a substring at the beginning of the input can not be matched by any of the regular expressions defined in the various tokens and the scanner is in state `header`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_script_error(t):\n",
    "    print(f\"Illegal character in state 'script': '{t.value[0]}'\")\n",
    "    t.lexer.skip(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line below is necessary to trick `ply.lex` into assuming this program is written in an ordiary python file instead of a *Jupyter notebook*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = 'main'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line below generates the scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexer = lex.lex(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we feed our input string into the generated scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexer.input(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to scan the data that we provided in the last line, we iterate over all tokens generated by our scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan(lexer):\n",
    "    for t in lexer:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan(lexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
